{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./myenv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./myenv/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in ./myenv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: nibabel in ./myenv/lib/python3.10/site-packages (5.3.2)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: tqdm in ./myenv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: wandb in ./myenv/lib/python3.10/site-packages (0.19.7)\n",
      "Requirement already satisfied: filelock in ./myenv/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./myenv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./myenv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./myenv/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./myenv/lib/python3.10/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./myenv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./myenv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./myenv/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in ./myenv/lib/python3.10/site-packages (from nibabel) (6.5.2)\n",
      "Requirement already satisfied: packaging>=20 in ./myenv/lib/python3.10/site-packages (from nibabel) (24.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in ./myenv/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./myenv/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./myenv/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in ./myenv/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in ./myenv/lib/python3.10/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./myenv/lib/python3.10/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in ./myenv/lib/python3.10/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in ./myenv/lib/python3.10/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./myenv/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./myenv/lib/python3.10/site-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in ./myenv/lib/python3.10/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in ./myenv/lib/python3.10/site-packages (from wandb) (75.6.0)\n",
      "Requirement already satisfied: six>=1.4.0 in ./myenv/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./myenv/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./myenv/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./myenv/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./myenv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./myenv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# python 3.10\n",
    "\n",
    "%pip install torch torchvision torchaudio nibabel numpy tqdm wandb\n",
    "\n",
    "DATASET = \"./DATA/ADNI_96\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.backends.mps.is_available())  # Should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal) device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (24s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rhysalexander/Desktop/FYP/code/wandb/run-20250304_011007-c38v345g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rhys-alexander/mri-alzheimers-classification/runs/c38v345g' target=\"_blank\">bright-silence-3</a></strong> to <a href='https://wandb.ai/rhys-alexander/mri-alzheimers-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rhys-alexander/mri-alzheimers-classification' target=\"_blank\">https://wandb.ai/rhys-alexander/mri-alzheimers-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rhys-alexander/mri-alzheimers-classification/runs/c38v345g' target=\"_blank\">https://wandb.ai/rhys-alexander/mri-alzheimers-classification/runs/c38v345g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 678 samples for train split\n",
      "Loaded 85 samples for val split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rhysalexander/Desktop/FYP/code/myenv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|‚ñè         | 6/339 [00:55<50:24,  9.08s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models.video as models\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# Check if Metal is available on macOS\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Metal) device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS not available, using CPU\")\n",
    "\n",
    "\n",
    "# Dataset class for loading .nii.gz files\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"train\"):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Get all files from AD and CN directories\n",
    "        ad_dir = os.path.join(root_dir, split, \"AD\")\n",
    "        cn_dir = os.path.join(root_dir, split, \"CN\")\n",
    "\n",
    "        # Load AD samples (label 1)\n",
    "        for file in os.listdir(ad_dir):\n",
    "            if file.endswith(\".nii.gz\"):\n",
    "                self.samples.append(os.path.join(ad_dir, file))\n",
    "                self.labels.append(1)  # AD class\n",
    "\n",
    "        # Load CN samples (label 0)\n",
    "        for file in os.listdir(cn_dir):\n",
    "            if file.endswith(\".nii.gz\"):\n",
    "                self.samples.append(os.path.join(cn_dir, file))\n",
    "                self.labels.append(0)  # CN class\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} samples for {split} split\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the .nii.gz file\n",
    "        img_path = self.samples[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load image using nibabel\n",
    "        img = nib.load(img_path)\n",
    "        img_data = img.get_fdata()\n",
    "\n",
    "        # Ensure the size is exactly 96x96x96\n",
    "        current_d, current_h, current_w = img_data.shape\n",
    "        if current_d != 96 or current_h != 96 or current_w != 96:\n",
    "            raise ValueError(\n",
    "                f\"Expected image size 96x96x96 but got {current_d}x{current_h}x{current_w}\"\n",
    "            )\n",
    "\n",
    "        # Convert to tensor and add channel dimension\n",
    "        img_tensor = torch.tensor(img_data, dtype=torch.float32).unsqueeze(\n",
    "            0\n",
    "        )  # Add channel dim\n",
    "\n",
    "        return img_tensor, label\n",
    "\n",
    "\n",
    "# Modified 3D ResNet model\n",
    "class MRIModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(MRIModel, self).__init__()\n",
    "        # Using a video ResNet and modifying it for 3D MRI\n",
    "        # Fix the deprecation warning by using weights parameter\n",
    "        self.resnet = models.r3d_18(weights=models.R3D_18_Weights.KINETICS400_V1)\n",
    "\n",
    "        # Replace the first layer to accept single-channel input instead of 3\n",
    "        self.resnet.stem[0] = nn.Conv3d(\n",
    "            1,\n",
    "            64,\n",
    "            kernel_size=(3, 7, 7),\n",
    "            stride=(1, 2, 2),\n",
    "            padding=(1, 3, 3),\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # Replace the final fully connected layer for binary classification\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: (B, 1, D, H, W)\n",
    "        return self.resnet(x)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Track batch-level metrics\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True)  # Faster than setting to zero\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels for metrics\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Log batch-level metrics\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"batch_loss\": loss.item(),\n",
    "                \"batch_acc\": 100 * (predicted == labels).sum().item() / labels.size(0),\n",
    "                \"batch\": epoch * len(dataloader) + batch_idx,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    # Class-wise accuracy\n",
    "    class_0_mask = all_labels == 0\n",
    "    class_1_mask = all_labels == 1\n",
    "\n",
    "    class_0_acc = (\n",
    "        100\n",
    "        * np.sum(all_preds[class_0_mask] == all_labels[class_0_mask])\n",
    "        / (np.sum(class_0_mask) + 1e-10)\n",
    "    )\n",
    "    class_1_acc = (\n",
    "        100\n",
    "        * np.sum(all_preds[class_1_mask] == all_labels[class_1_mask])\n",
    "        / (np.sum(class_1_mask) + 1e-10)\n",
    "    )\n",
    "\n",
    "    # Log epoch-level metrics\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"train_loss\": epoch_loss,\n",
    "            \"train_acc\": epoch_acc,\n",
    "            \"train_CN_acc\": class_0_acc,\n",
    "            \"train_AD_acc\": class_1_acc,\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "# Validation function\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Track for metrics\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # For accuracy\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Store for metrics\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())  # Probability of AD class\n",
    "\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_acc = 100 * correct / total\n",
    "\n",
    "    # Convert to numpy for metric calculation\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Class-wise accuracy\n",
    "    class_0_mask = all_labels == 0\n",
    "    class_1_mask = all_labels == 1\n",
    "\n",
    "    class_0_acc = (\n",
    "        100\n",
    "        * np.sum(all_preds[class_0_mask] == all_labels[class_0_mask])\n",
    "        / (np.sum(class_0_mask) + 1e-10)\n",
    "    )\n",
    "    class_1_acc = (\n",
    "        100\n",
    "        * np.sum(all_preds[class_1_mask] == all_labels[class_1_mask])\n",
    "        / (np.sum(class_1_mask) + 1e-10)\n",
    "    )\n",
    "\n",
    "    # Custom metrics\n",
    "    true_positives = np.sum((all_preds == 1) & (all_labels == 1))\n",
    "    false_positives = np.sum((all_preds == 1) & (all_labels == 0))\n",
    "    true_negatives = np.sum((all_preds == 0) & (all_labels == 0))\n",
    "    false_negatives = np.sum((all_preds == 0) & (all_labels == 1))\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives + 1e-10)\n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-10)\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "    # Generate confusion matrix for visualization\n",
    "    confusion_matrix = wandb.plot.confusion_matrix(\n",
    "        preds=all_preds, y_true=all_labels, class_names=[\"CN\", \"AD\"]\n",
    "    )\n",
    "\n",
    "    # ROC curve for validation\n",
    "    roc_curve = wandb.plot.roc_curve(\n",
    "        all_labels,\n",
    "        [1 - p for p in all_probs]\n",
    "        + all_probs,  # Need [CN_prob, AD_prob] probabilities for each sample\n",
    "        classes_to_plot=[1],  # Plot ROC for AD class (positive class)\n",
    "        labels=[\"CN\", \"AD\"],\n",
    "    )\n",
    "\n",
    "    # Log validation metrics\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_CN_acc\": class_0_acc,\n",
    "            \"val_AD_acc\": class_1_acc,\n",
    "            \"val_precision\": precision,\n",
    "            \"val_recall\": recall,\n",
    "            \"val_f1\": f1_score,\n",
    "            \"confusion_matrix\": confusion_matrix,\n",
    "            \"roc_curve\": roc_curve,\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize wandb\n",
    "    wandb.init(\n",
    "        project=\"mri-alzheimers-classification\",\n",
    "        config={\n",
    "            \"architecture\": \"3D-ResNet18\",\n",
    "            \"dataset\": \"MRI-AD-CN\",\n",
    "            \"epochs\": 5,\n",
    "            \"batch_size\": 2,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"device\": str(device),\n",
    "            \"input_dimensions\": \"128x128x128\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Parameters\n",
    "    data_root = DATASET  # Update this to your dataset path\n",
    "    batch_size = 2  # Reduced batch size for memory constraints\n",
    "    num_epochs = 5\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = MRIDataset(data_root, split=\"train\")\n",
    "    val_dataset = MRIDataset(data_root, split=\"val\")\n",
    "\n",
    "    # Log dataset stats\n",
    "    wandb.config.update(\n",
    "        {\n",
    "            \"train_samples\": len(train_dataset),\n",
    "            \"val_samples\": len(val_dataset),\n",
    "            \"train_AD_samples\": train_dataset.labels.count(1),\n",
    "            \"train_CN_samples\": train_dataset.labels.count(0),\n",
    "            \"val_AD_samples\": val_dataset.labels.count(1),\n",
    "            \"val_CN_samples\": val_dataset.labels.count(0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=0\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    model = MRIModel(num_classes=2)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Log model architecture\n",
    "    wandb.watch(model, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "    # Learning rate scheduler for better convergence\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, epoch\n",
    "        )\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "        # Update learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "            # Log best model as artifact\n",
    "            artifact = wandb.Artifact(\"best_model\", type=\"model\")\n",
    "            artifact.add_file(\"best_model.pth\")\n",
    "            wandb.log_artifact(artifact)\n",
    "\n",
    "    # Close wandb run\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
