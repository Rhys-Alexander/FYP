{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.10\n",
    "\n",
    "%pip install torch torchvision torchaudio torchinfo nibabel numpy tqdm wandb monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models.video as models\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nilearn import plotting\n",
    "from torchinfo import torchinfo\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    RandRotate90,\n",
    "    RandFlip,\n",
    "    RandGaussianNoise,\n",
    "    RandGaussianSmooth,\n",
    "    RandAdjustContrast,\n",
    "    RandScaleIntensity,\n",
    "    NormalizeIntensity,\n",
    ")\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./DATA/ADNI_CROPPED_128\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Scans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_scans(dataset_path, split=\"train\", num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize the first few MRI scans from AD and CN directories.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the dataset directory.\n",
    "        split (str): Dataset split to visualize ('train', 'val', 'test').\n",
    "        num_samples (int): Number of samples to visualize from each class.\n",
    "    \"\"\"\n",
    "    # Define directories for AD and CN\n",
    "    ad_dir = os.path.join(dataset_path, split, \"AD\")\n",
    "    cn_dir = os.path.join(dataset_path, split, \"CN\")\n",
    "\n",
    "    # Get the first few files from each directory\n",
    "    ad_files = [\n",
    "        os.path.join(ad_dir, f) for f in os.listdir(ad_dir) if f.endswith(\".nii.gz\")\n",
    "    ][:num_samples]\n",
    "    cn_files = [\n",
    "        os.path.join(cn_dir, f) for f in os.listdir(cn_dir) if f.endswith(\".nii.gz\")\n",
    "    ][:num_samples]\n",
    "\n",
    "    # Plot the first few AD scans\n",
    "    print(\"AD Scans:\")\n",
    "    for file in ad_files:\n",
    "        plotting.plot_anat(file, title=os.path.basename(file))\n",
    "    plotting.show()\n",
    "\n",
    "    # Plot the first few CN scans\n",
    "    print(\"CN Scans:\")\n",
    "    for file in cn_files:\n",
    "        plotting.plot_anat(file, title=os.path.basename(file))\n",
    "    plotting.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# visualize_scans(DATASET, split=\"train\", num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Metal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Metal is available on macOS\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Metal) device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS not available, using CPU\")\n",
    "\n",
    "if device.type == \"mps\":\n",
    "    # Empty CUDA cache periodically during training to avoid memory fragmentation\n",
    "    def empty_cache():\n",
    "        try:\n",
    "            # For newer PyTorch versions with MPS cache management\n",
    "            torch.mps.empty_cache()\n",
    "        except:\n",
    "            print(\"MPS cache management not available\")\n",
    "            pass  # Ignore if this function doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        split=\"train\",\n",
    "        apply_augmentation=False,\n",
    "        target_size=(128, 128, 128),\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.apply_augmentation = apply_augmentation\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # Validate inputs\n",
    "        if split not in [\"train\", \"val\", \"test\"]:\n",
    "            raise ValueError(\n",
    "                f\"Split must be one of 'train', 'val', 'test', got {split}\"\n",
    "            )\n",
    "\n",
    "        # Get all files from AD and CN directories\n",
    "        ad_dir = os.path.join(root_dir, split, \"AD\")\n",
    "        cn_dir = os.path.join(root_dir, split, \"CN\")\n",
    "\n",
    "        if not os.path.exists(ad_dir):\n",
    "            raise FileNotFoundError(f\"AD directory not found at {ad_dir}\")\n",
    "        if not os.path.exists(cn_dir):\n",
    "            raise FileNotFoundError(f\"CN directory not found at {cn_dir}\")\n",
    "\n",
    "        self._load_samples(ad_dir, cn_dir)\n",
    "        self._setup_transforms()\n",
    "\n",
    "        print(f\"Loaded {len(self.samples)} samples for {split} split\")\n",
    "        print(f\"Augmentation applied: {apply_augmentation}\")\n",
    "\n",
    "    def _load_samples(self, ad_dir, cn_dir):\n",
    "        \"\"\"Load samples from AD and CN directories\"\"\"\n",
    "        # Load AD samples (label 1)\n",
    "        ad_files = [f for f in os.listdir(ad_dir) if f.endswith(\".nii.gz\")]\n",
    "        for file in ad_files:\n",
    "            self.samples.append(os.path.join(ad_dir, file))\n",
    "            self.labels.append(1)  # AD class\n",
    "\n",
    "        # Load CN samples (label 0)\n",
    "        cn_files = [f for f in os.listdir(cn_dir) if f.endswith(\".nii.gz\")]\n",
    "        for file in cn_files:\n",
    "            self.samples.append(os.path.join(cn_dir, file))\n",
    "            self.labels.append(0)  # CN class\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(f\"No .nii.gz files found in {ad_dir} or {cn_dir}\")\n",
    "\n",
    "    def _setup_transforms(self):\n",
    "        \"\"\"Setup image transformations based on augmentation flag\"\"\"\n",
    "        if self.apply_augmentation:\n",
    "            self.transforms = Compose(\n",
    "                [\n",
    "                    RandRotate90(prob=0.5, spatial_axes=(1, 2)),\n",
    "                    RandFlip(prob=0.5, spatial_axis=0),\n",
    "                    RandGaussianNoise(prob=0.2, mean=0.0, std=0.1),\n",
    "                    RandGaussianSmooth(prob=0.2, sigma_x=(0.5, 1.5)),\n",
    "                    RandAdjustContrast(prob=0.3, gamma=(0.7, 1.3)),\n",
    "                    RandScaleIntensity(prob=0.3, factors=0.2),\n",
    "                    NormalizeIntensity(nonzero=True),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transforms = Compose([NormalizeIntensity(nonzero=True)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the .nii.gz file\n",
    "        img_path = self.samples[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            # Load image using nibabel\n",
    "            img = nib.load(img_path)\n",
    "            img_data = img.get_fdata()\n",
    "\n",
    "            # Validate image dimensions\n",
    "            expected_d, expected_h, expected_w = self.target_size\n",
    "            current_d, current_h, current_w = img_data.shape\n",
    "\n",
    "            if (\n",
    "                current_d != expected_d\n",
    "                or current_h != expected_h\n",
    "                or current_w != expected_w\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    f\"Expected image size {expected_d}x{expected_h}x{expected_w} \"\n",
    "                    f\"but got {current_d}x{current_h}x{current_w} for {img_path}\"\n",
    "                )\n",
    "\n",
    "            # Add channel dimension to numpy array\n",
    "            img_data = np.expand_dims(img_data, axis=0)\n",
    "\n",
    "            # Apply transforms\n",
    "            img_data = self.transforms(img_data)\n",
    "\n",
    "            # Convert to tensor if not already a tensor\n",
    "            if not isinstance(img_data, torch.Tensor):\n",
    "                img_data = torch.tensor(img_data, dtype=torch.float32)\n",
    "\n",
    "            # Ensure the label is also a tensor\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "            return img_data, label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            # Return a default or raise the exception\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified 3D ResNet model with layer freezing\n",
    "class MRIModel(nn.Module):\n",
    "    def __init__(self, num_classes=2, freeze_layers=True):\n",
    "        super(MRIModel, self).__init__()\n",
    "        # Using a video ResNet and modifying it for 3D MRI\n",
    "        self.resnet = models.r3d_18(weights=models.R3D_18_Weights.KINETICS400_V1)\n",
    "\n",
    "        # Replace the first layer to accept single-channel input instead of 3\n",
    "        self.resnet.stem[0] = nn.Conv3d(\n",
    "            1,\n",
    "            64,\n",
    "            kernel_size=(3, 7, 7),\n",
    "            stride=(1, 2, 2),\n",
    "            padding=(1, 3, 3),\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # Replace the final fully connected layer for binary classification\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        # Freeze specific layers if requested\n",
    "        if freeze_layers:\n",
    "            self._freeze_layers()\n",
    "\n",
    "    def _freeze_layers(self):\n",
    "        \"\"\"Freeze most layers of the ResNet model, leaving only layer4 and fc unfrozen\"\"\"\n",
    "        # Freeze stem and layers 1-3\n",
    "        # TODO loook at model in more detail and see where to freeze\n",
    "        for name, param in self.resnet.named_parameters():\n",
    "            if \"layer4\" not in name and \"fc\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def count_trainable_params(self):\n",
    "        \"\"\"Count and return trainable parameters\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def count_total_params(self):\n",
    "        \"\"\"Count and return total parameters\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: (B, 1, D, H, W)\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_summary(model, input_size=(1, 1, 128, 128, 128), detailed=True):\n",
    "    \"\"\"\n",
    "    Display a comprehensive summary of the model architecture and parameters.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model to analyze\n",
    "        input_size: The input tensor size (batch_size, channels, depth, height, width)\n",
    "        detailed: Whether to show detailed layer information\n",
    "    \"\"\"\n",
    "    # Get basic model summary using torchinfo\n",
    "    summary = torchinfo.summary(\n",
    "        model,\n",
    "        input_size=input_size,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    print(f\"MODEL ARCHITECTURE SUMMARY:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(summary)\n",
    "\n",
    "    # Count parameters by layer type\n",
    "    layer_counts = {}\n",
    "    for name, module in model.named_modules():\n",
    "        layer_type = module.__class__.__name__\n",
    "        if layer_type not in layer_counts:\n",
    "            layer_counts[layer_type] = {\"count\": 0, \"params\": 0, \"trainable_params\": 0}\n",
    "\n",
    "        layer_counts[layer_type][\"count\"] += 1\n",
    "        params = sum(p.numel() for p in module.parameters(recurse=False))\n",
    "        trainable_params = sum(\n",
    "            p.numel() for p in module.parameters(recurse=False) if p.requires_grad\n",
    "        )\n",
    "\n",
    "        layer_counts[layer_type][\"params\"] += params\n",
    "        layer_counts[layer_type][\"trainable_params\"] += trainable_params\n",
    "\n",
    "    # Create detailed layer information dataframe\n",
    "    if detailed:\n",
    "        layers_info = []\n",
    "        for name, module in model.named_modules():\n",
    "            if len(list(module.children())) == 0:  # Only leaf modules\n",
    "                params = sum(p.numel() for p in module.parameters())\n",
    "                trainable = sum(\n",
    "                    p.numel() for p in module.parameters() if p.requires_grad\n",
    "                )\n",
    "\n",
    "                layers_info.append(\n",
    "                    {\n",
    "                        \"Layer\": name,\n",
    "                        \"Type\": module.__class__.__name__,\n",
    "                        \"Parameters\": params,\n",
    "                        \"Trainable\": trainable,\n",
    "                        \"Frozen\": params - trainable,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Create and display DataFrame\n",
    "        df = pd.DataFrame(layers_info)\n",
    "        if not df.empty:\n",
    "            print(\"\\nDETAILED LAYER INFORMATION:\")\n",
    "            print(\"=\" * 80)\n",
    "            display(df)\n",
    "\n",
    "    # Show frozen vs trainable stats\n",
    "    total_params = model.count_total_params()\n",
    "    trainable_params = model.count_trainable_params()\n",
    "    frozen_params = total_params - trainable_params\n",
    "\n",
    "    print(\"\\nPARAMETER STATISTICS:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total parameters:    {total_params:,}\")\n",
    "    print(\n",
    "        f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Frozen parameters:    {frozen_params:,} ({frozen_params/total_params*100:.2f}%)\"\n",
    "    )\n",
    "\n",
    "    # Display model architecture as text\n",
    "    print(\"\\nMODEL ARCHITECTURE DETAILS:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(model)\n",
    "\n",
    "    # Return summary for potential further use\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# model = MRIModel(num_classes=2, freeze_layers=True)\n",
    "# display_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train model for one epoch with optimized PyTorch practices.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        dataloader: Training data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        device: Computation device (CPU/GPU/MPS)\n",
    "        epoch: Current epoch number\n",
    "\n",
    "    Returns:\n",
    "        tuple: (epoch_loss, epoch_accuracy)\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Use tensors instead of scalar values\n",
    "    running_loss_tensor = torch.tensor(0.0, device=device)\n",
    "    correct_tensor = torch.tensor(0, device=device)\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        # Move data to device with non_blocking for potential performance gain\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss_tensor += loss\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct_tensor += (predicted == labels).sum()  # Keep as tensor\n",
    "\n",
    "    # Convert accumulated tensors to scalars ONCE at the end\n",
    "    epoch_loss = running_loss_tensor.item() / total\n",
    "    epoch_acc = 100 * correct_tensor.item() / total\n",
    "\n",
    "    # Log epoch-level metrics\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"train_loss\": epoch_loss,\n",
    "            \"train_acc\": epoch_acc,\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(all_labels, all_preds, all_probs):\n",
    "    \"\"\"Calculate and return classification metrics.\"\"\"\n",
    "    # Convert to numpy if they aren't already\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Class-wise accuracy\n",
    "    class_0_mask = all_labels == 0\n",
    "    class_1_mask = all_labels == 1\n",
    "\n",
    "    class_0_acc = (\n",
    "        100\n",
    "        * np.sum(all_preds[class_0_mask] == all_labels[class_0_mask])\n",
    "        / (np.sum(class_0_mask) + 1e-10)\n",
    "    )\n",
    "    class_1_acc = (\n",
    "        100\n",
    "        * np.sum(all_preds[class_1_mask] == all_labels[class_1_mask])\n",
    "        / (np.sum(class_1_mask) + 1e-10)\n",
    "    )\n",
    "\n",
    "    # Calculate confusion matrix values\n",
    "    true_positives = np.sum((all_preds == 1) & (all_labels == 1))\n",
    "    false_positives = np.sum((all_preds == 1) & (all_labels == 0))\n",
    "    true_negatives = np.sum((all_preds == 0) & (all_labels == 0))\n",
    "    false_negatives = np.sum((all_preds == 0) & (all_labels == 1))\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives + 1e-10)\n",
    "    recall = true_positives / (true_positives + false_negatives + 1e-10)\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "\n",
    "    return {\n",
    "        \"class_0_acc\": class_0_acc,\n",
    "        \"class_1_acc\": class_1_acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"confusion_data\": {\n",
    "            \"true_positives\": true_positives,\n",
    "            \"false_positives\": false_positives,\n",
    "            \"true_negatives\": true_negatives,\n",
    "            \"false_negatives\": false_negatives,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def create_wandb_visualizations(all_labels, all_preds, all_probs):\n",
    "    \"\"\"Create and return W&B visualization objects.\"\"\"\n",
    "    # Generate confusion matrix\n",
    "    confusion_matrix = wandb.plot.confusion_matrix(\n",
    "        preds=all_preds, y_true=all_labels, class_names=[\"CN\", \"AD\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Create proper format for probabilities\n",
    "        y_probas = np.zeros((len(all_labels), 2))\n",
    "        y_probas[:, 0] = 1 - np.array(all_probs)  # CN probabilities\n",
    "        y_probas[:, 1] = np.array(all_probs)  # AD probabilities\n",
    "\n",
    "        # Generate ROC curve\n",
    "        roc_curve = wandb.plot.roc_curve(\n",
    "            all_labels,\n",
    "            y_probas,\n",
    "            classes_to_plot=[1],  # Plot ROC for AD class (positive class)\n",
    "            labels=[\"CN\", \"AD\"],\n",
    "        )\n",
    "        return {\"confusion_matrix\": confusion_matrix, \"roc_curve\": roc_curve}\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: ROC curve calculation failed: {e}\")\n",
    "        return {\"confusion_matrix\": confusion_matrix}\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"Validate the model and return performance metrics.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Track predictions and labels\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Store predictions and labels\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    val_loss = running_loss / len(dataloader)\n",
    "    val_acc = 100 * correct / total\n",
    "\n",
    "    # Calculate detailed metrics\n",
    "    metrics = calculate_classification_metrics(all_labels, all_preds, all_probs)\n",
    "\n",
    "    # Generate visualizations\n",
    "    viz = create_wandb_visualizations(all_labels, all_preds, all_probs)\n",
    "\n",
    "    # Log to W&B\n",
    "    log_dict = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_CN_acc\": metrics[\"class_0_acc\"],\n",
    "        \"val_AD_acc\": metrics[\"class_1_acc\"],\n",
    "        \"val_precision\": metrics[\"precision\"],\n",
    "        \"val_recall\": metrics[\"recall\"],\n",
    "        \"val_f1\": metrics[\"f1_score\"],\n",
    "        \"confusion_matrix\": viz[\"confusion_matrix\"],\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "\n",
    "    if \"roc_curve\" in viz:\n",
    "        log_dict[\"roc_curve\"] = viz[\"roc_curve\"]\n",
    "\n",
    "    wandb.log(log_dict)\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize wandb\n",
    "    wandb.init(\n",
    "        project=\"mri-alzheimers-classification\",\n",
    "        config={\n",
    "            \"architecture\": \"3D-ResNet18-FrozenLayers\",\n",
    "            \"dataset\": \"MRI-AD-CN\",\n",
    "            \"epochs\": 20,\n",
    "            \"batch_size\": 2,\n",
    "            \"learning_rate\": 0.0001,\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"device\": str(device),\n",
    "            \"input_dimensions\": \"128x128x128\",\n",
    "            \"freeze_layers\": True,\n",
    "            \"data_augmentation\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Parameters\n",
    "    data_root = DATASET  # Update this to your dataset path\n",
    "    batch_size = 2  # Reduced batch size for memory constraints\n",
    "    num_epochs = 20  # Reduced epochs for testing\n",
    "    learning_rate = 0.0001\n",
    "    freeze_layers = True\n",
    "    use_augmentation = True\n",
    "\n",
    "    # Create datasets with augmentation for training\n",
    "    train_dataset = MRIDataset(\n",
    "        data_root, split=\"train\", apply_augmentation=use_augmentation\n",
    "    )\n",
    "    val_dataset = MRIDataset(\n",
    "        data_root, split=\"val\", apply_augmentation=False\n",
    "    )  # No augmentation for validation\n",
    "\n",
    "    # Log dataset stats\n",
    "    wandb.config.update(\n",
    "        {\n",
    "            \"train_samples\": len(train_dataset),\n",
    "            \"val_samples\": len(val_dataset),\n",
    "            \"train_AD_samples\": train_dataset.labels.count(1),\n",
    "            \"train_CN_samples\": train_dataset.labels.count(0),\n",
    "            \"val_AD_samples\": val_dataset.labels.count(1),\n",
    "            \"val_CN_samples\": val_dataset.labels.count(0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # Initialize the model with layer freezing\n",
    "    model = MRIModel(num_classes=2, freeze_layers=freeze_layers)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Log parameter statistics\n",
    "    trainable_params = model.count_trainable_params()\n",
    "    total_params = model.count_total_params()\n",
    "    frozen_params = total_params - trainable_params\n",
    "\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(\n",
    "        f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%})\"\n",
    "    )\n",
    "    print(f\"Frozen parameters: {frozen_params:,} ({frozen_params/total_params:.2%})\")\n",
    "\n",
    "    # Log model architecture and parameter stats\n",
    "    wandb.config.update(\n",
    "        {\n",
    "            \"total_params\": total_params,\n",
    "            \"trainable_params\": trainable_params,\n",
    "            \"frozen_params\": frozen_params,\n",
    "            \"frozen_percentage\": frozen_params / total_params,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    wandb.watch(model, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Loss function with class weighting to handle imbalance\n",
    "    # Calculate class weights based on sample distribution\n",
    "    num_ad = train_dataset.labels.count(1)\n",
    "    num_cn = train_dataset.labels.count(0)\n",
    "    total = num_ad + num_cn\n",
    "\n",
    "    # Inverse frequency weighting\n",
    "    weight_cn = total / (2 * num_cn) if num_cn > 0 else 1.0\n",
    "    weight_ad = total / (2 * num_ad) if num_ad > 0 else 1.0\n",
    "\n",
    "    class_weights = torch.tensor([weight_cn, weight_ad], device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    # Optimizer with parameter groups and different learning rates\n",
    "    # Higher learning rate for new/unfrozen layers, lower for pre-trained unfrozen layers\n",
    "    fc_params = list(model.resnet.fc.parameters())\n",
    "    other_params = [\n",
    "        p\n",
    "        for name, p in model.named_parameters()\n",
    "        if p.requires_grad and not any(p is fc_param for fc_param in fc_params)\n",
    "    ]\n",
    "\n",
    "    # Set up parameter groups with different learning rates\n",
    "    param_groups = [\n",
    "        {\"params\": other_params, \"lr\": learning_rate},\n",
    "        {\n",
    "            \"params\": fc_params,\n",
    "            \"lr\": learning_rate * 10,\n",
    "        },  # Higher learning rate for final layer\n",
    "    ]\n",
    "\n",
    "    optimizer = optim.AdamW(param_groups, lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "    # Learning rate scheduler with cosine annealing for better convergence\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=5, T_mult=1, eta_min=learning_rate / 100\n",
    "    )\n",
    "\n",
    "    # Early stopping implementation\n",
    "    patience = 5\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    # Check for checkpoint and load if exists\n",
    "    checkpoint_path = \"checkpoints/checkpoint.pth\"\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_val_acc = checkpoint.get(\n",
    "            \"best_val_acc\", 0.0\n",
    "        )  # Handle if best_val_acc wasn't saved.\n",
    "        best_val_loss = checkpoint.get(\"best_val_loss\", float(\"inf\"))\n",
    "        print(f\"Loaded checkpoint from epoch {start_epoch}\")\n",
    "    else:\n",
    "        best_val_acc = 0.0\n",
    "        best_val_loss = float(\"inf\")\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, epoch\n",
    "        )\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device, epoch)\n",
    "\n",
    "        # Update learning rate based on scheduler\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Current learning rate: {current_lr:.6f}\")\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save the best model by validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"val_acc\": val_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                },\n",
    "                \"best_model_acc.pth\",\n",
    "            )\n",
    "            print(\"Model saved (best accuracy)!\")\n",
    "\n",
    "            # Log best model as artifact\n",
    "            artifact = wandb.Artifact(\"best_model_acc\", type=\"model\")\n",
    "            artifact.add_file(\"best_model_acc.pth\")\n",
    "            wandb.log_artifact(artifact)\n",
    "\n",
    "            # Reset early stopping counter on improvement\n",
    "            early_stopping_counter = 0\n",
    "\n",
    "        # Save best model by validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"val_acc\": val_acc,\n",
    "                    \"val_loss\": val_loss,\n",
    "                },\n",
    "                \"best_model_loss.pth\",\n",
    "            )\n",
    "            print(\"Model saved (best loss)!\")\n",
    "\n",
    "            # Log best model as artifact\n",
    "            artifact = wandb.Artifact(\"best_model_loss\", type=\"model\")\n",
    "            artifact.add_file(\"best_model_loss.pth\")\n",
    "            wandb.log_artifact(artifact)\n",
    "        else:\n",
    "            # Increment early stopping counter\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        # Check for early stopping\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs without improvement.\")\n",
    "            break\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"best_val_acc\": best_val_acc,\n",
    "                \"best_val_loss\": best_val_loss,\n",
    "            },\n",
    "            checkpoint_path,\n",
    "        )\n",
    "\n",
    "        if device.type == \"mps\":\n",
    "            empty_cache()\n",
    "\n",
    "    # Create test dataset and dataloader\n",
    "    test_dataset = MRIDataset(\n",
    "        data_root, split=\"test\", apply_augmentation=False\n",
    "    )  # No augmentation for test set\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # After training, load best model for final evaluation\n",
    "    checkpoint = torch.load(\"best_model_acc.pth\")\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(\n",
    "        f\"Loaded best model from epoch {checkpoint['epoch']+1} with accuracy {checkpoint['val_acc']:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    final_test_loss, final_test_acc = validate(\n",
    "        model, test_loader, criterion, device, num_epochs\n",
    "    )\n",
    "    print(f\"Final test accuracy: {final_test_acc:.2f}%\")\n",
    "\n",
    "    # Log final model summary\n",
    "    wandb.run.summary[\"best_val_acc\"] = best_val_acc\n",
    "    wandb.run.summary[\"best_val_loss\"] = best_val_loss\n",
    "    wandb.run.summary[\"final_val_acc\"] = final_test_acc\n",
    "    wandb.run.summary[\"final_val_loss\"] = final_test_loss\n",
    "    wandb.run.summary[\"total_epochs\"] = epoch + 1 if \"epoch\" in locals() else 0\n",
    "\n",
    "    # Close wandb run\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    if not os.path.exists(\"checkpoints\"):\n",
    "        os.makedirs(\"checkpoints\")\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
