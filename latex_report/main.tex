\documentclass[12pt, a4paper]{article}


% A pretty common set of packages
\usepackage[margin=2.5cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{color}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{engord}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{parskip}
\usepackage{setspace}
\usepackage{titlesec}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage[UKenglish]{babel}
\usepackage[UKenglish]{isodate}
\usepackage[skip=2pt,font=footnotesize,justification=centering]{caption}
% \usepackage{natbib}
\usepackage[colorlinks=true, 
    linkcolor=blue,          % color of internal links
    citecolor=blue,        % color of links to bibliography
    filecolor=blue,      % color of file links
    urlcolor=blue]{hyperref}




% Do you prefer Sans Serif fonts?
%\usepackage{sfmath}
%\renewcommand{\familydefault}{\sfdefault} 




% Make some additional useful commands
\newcommand{\ie}{\emph{i.e.}\ }
\newcommand{\eg}{\emph{e.g.}\ }
\newcommand{\etal}{\emph{et al}}
\newcommand{\sub}[1]{$_{\textrm{#1}}$}
\newcommand{\super}[1]{$^{\textrm{#1}}$}
\newcommand{\degC}{$^{\circ}$C}
\newcommand{\wig}{$\sim$}
\newcommand{\ord}[1]{\engordnumber{#1}}
\newcommand{\num}[2]{$#1\,$#2}
\newcommand{\range}[3]{$#1$-$#2\,$#3}
\newcommand{\roughly}[2]{$\sim\!#1\,$#2}
\newcommand{\area}[3]{$#1 \! \times \! #2\,$#3}
\newcommand{\vol}[4]{$#1 \! \times \! #2 \! \times \! #3\,$#4}
\newcommand{\cube}[1]{$#1 \! \times \! #1 \! \times \! #1$}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\eqnref}[1]{Equation~\ref{#1}}
\newcommand{\tableref}[1]{Table~\ref{#1}}
\newcommand{\secref}[1]{Section \ref{#1}}
\newcommand{\XC}{\emph{exchange-correlation}}
\newcommand{\abinit}{\emph{ab initio}}
\newcommand{\Abinit}{\emph{Ab initio}}
\newcommand{\Lonetwo}{L1$_{2}$}
\newcommand{\Dznt}{D0$_{19}$}
\newcommand{\Dtf}{D8$_{5}$}
\newcommand{\Btwo}{B$_{2}$}
\newcommand{\fcc}{\emph{fcc}}
\newcommand{\hcp}{\emph{hcp}}
\newcommand{\bcc}{\emph{bcc}}
\newcommand{\Ang}{{\AA}}
\newcommand{\inverseAng}{{\AA}$^{-1}$}
%\newcommand{\comment}[1]{}
\newcommand{\comment}[1]{\textcolor{red}{[COMMENT: #1]}}
\newcommand{\more}{\textcolor{red}{[MORE]}}
\newcommand{\red}[1]{\textcolor{red}{#1}}





% Change this to modify look of header and footer
\lhead{}
\chead{}
\rhead{}
\lfoot{}
\cfoot{\thepage{}}
\rfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\begin{document}

\onehalfspacing


\begin{titlepage}

\begin{center}
\includegraphics[width=1in]{figures/bham_crest}

\vspace{0.3in}

\includegraphics[width=3in]{figures/bham_logo}

\vspace{2in}

{\LARGE Transfer Learning for Alzheimer’s Disease Detection: Adapting Video Classification Models for MRI Scans }

\vspace{0.7in}

{\Large Rhys W. Alexander (2458177)}


\vfill{}
Final project report submitted\\ 
in partial fulfilment for the degree of\\
B.SCI. IN ARTIFICIAL INTELLIGENCE AND COMPUTER SCIENCE
\end{center}

\vspace{0.4in}
Date: \today{}     \hfill{} Project supervisor: \\
Word count: X,XXX   \hfill{} Dr Rickson Mesquita
\end{titlepage}






\tableofcontents

\newpage{}










\section{Abstract}
% 250 words

% - Brief overview of the problem and motivation
% - Summary of methodology and main contributions
% - Key results and conclusions
% - Implications and significance

\section{Introduction}
% 1,000 words

% - **Problem statement**
%   - Challenges in Alzheimer's disease diagnosis
%   - Importance of early and accurate detection
%   - Role of neuroimaging in diagnosis
% - **Motivation**
%   - Clinical importance of automating AD detection
%   - Limitations of current diagnostic approaches
%   - Why T1-weighted MRI is particularly valuable (accessibility, non-invasive, etc.)
% - **Research objectives**
%   - Examine transfer learning from video models to 3D MRI analysis
%   - Compare 3D CNN performance to alternative approaches
%   - Identify brain regions contributing to model decisions
% - **Novel contributions**
%   - Application of pre-trained video classification models for MRI analysis
%   - Domain-specific preprocessing pipeline for structural brain MRI
%   - Subject-level validation methodology preventing data leakage
% - **Dissertation roadmap**
%   - Brief outline of subsequent chapters


\section{Literature review}
% 2,000 words 

% - **Alzheimer's Disease and Neuroimaging**

%   - Pathophysiology with emphasis on structural changes
%   - Medical background of AD (emphasize hippocampal atrophy as key biomarker)
%   - Other neuroimaging markers (ventricular enlargement, cortical thinning)
%   - Limitations of visual assessment by radiologists
%   - Current clinical diagnostic practices and their limitations
%   - Role of structural MRI in diagnosis
%   - Advantages of T1-weighted imaging for AD detection

% - **Deep Learning for Medical Image Analysis**

%   - Evolution from traditional ML to deep learning in medical imaging
%   - 2D vs. 3D approaches for volumetric data
%   - Transfer learning in medical imaging context
%   - Challenges in deep learning for medical imaging (data scarcity, interpretability)

% - **3D Deep Learning Architectures**

%   - 3D CNN architectures (ResNet and variants)
%   - Vision transformers for volumetric data
%   - Video classification models and their adaptation to medical data
%   - Performance comparisons from existing literature

% - **MRI Preprocessing for Deep Learning**

%   - Skull stripping methodologies
%   - Registration and normalization approaches
%   - Impact of preprocessing on model performance
%   - Current best practices

% - **Current State of the Art**
%   - Recent advances in automated AD detection
%   - Performance benchmarks and limitations
%   - Gap addressed by this research


\section{Methodology}
% 2,500 words

% - **Data Acquisition and Characteristics**

%   - ADNI dataset description and selection criteria
%   - Patient demographics and diagnostic criteria
%   - MRI acquisition parameters (focusing on T1w MPRAGE)
%   - Data distribution analysis (balance, demographics)

% - **Comprehensive Preprocessing Pipeline**

%   - DICOM to NIfTI conversion
%   - Skull stripping using SynthStrip (justification over alternatives)
%   - Voxel standardization to 1×1×1mm
%   - Cropping and reshaping strategy (128×128×128)
%   - Bias field correction and orientation standardization
%   - Rationale for omitting spatial normalization

% - **Data Splitting Strategy**

%   - Subject-level splitting methodology
%   - Round-robin approach for balanced distribution
%   - Final distribution statistics (subjects and scans per split)
%   - Prevention of data leakage concerns

% - **Data Augmentation**

%   - Augmentation techniques implemented (affine transformations, noise, gamma)
%   - Justification for chosen techniques
%   - Impact on model generalization

% - **Model Architectures**

%   - 3D ResNet, r3d18, architecture details
%   - Transfer learning from Kinetics400 pre-training
%   - Layer freezing strategy with rationale
%   - Alternative architectures explored - MC318
%   - MViT investigation and memory constraint challenges
%   - Parameter counts and computational considerations
%   - Implementation details - PyTorch, Weights \& Biases

% - **Training Framework and Implementation**

%   - PyTorch implementation with Weights \& Biases integration
%   - Hyperparameter selection process
%   - batch size
%   - Early stopping criteria
%   - Loss function (weighted cross-entropy) and optimization strategy
%   - Learning rate scheduling approach
%   - Hardware configuration and constraints
%   - Computational optimizations attempted

% - **Evaluation Methodology**
%   - Classification metrics selection and justification
%   - Validation strategy
%   - Statistical analysis approach
%   - Cross-validation approach

\section{Results}
% 2,000 words

% - **Overall Performance Metrics**

%   - Classification accuracy, precision, recall, F1-score
%   - ROC curves and AUC analysis
%   - Confusion matrices and interpretation
%   - k fold Cross-validation results and stability analysis
%   - Statistical significance testing
%   - Benchmarking against literature results
%   - Bayesian analysis on representative populations

% - **Architectural Comparisons**

%   - 3D ResNet vs. Mixed Convolution performance
%   - Impact of layer freezing strategies
%   - Parameter efficiency analysis

% - **Preprocessing Impact Analysis**

%   - Effect of different preprocessing steps
%   - Importance of crop-and-reshape vs. simple interpolation
%   - Impact of skull stripping quality

% - **Augmentation Effectiveness**

%   - Comparative analysis of different augmentation strategies
%   - Quantitative impact on model performance

% - **Training Dynamics**

%   - Learning curves analysis
%   - Convergence patterns
%   - Overfitting observations and mitigations

% - **Error Analysis**

%   - Patterns in misclassifications
%   - Subject-level vs. scan-level errors
%   - Potential confounding factors

% - **Visual Results**
%   - Key visualizations from Weights \& Biases
%   - Representative case studies
%   - Visualization of model attention/activation maps XAI


\section{Discussion}
% 2,000 words

% - **Interpretation of Results**

%   - Critical analysis of performance metrics
%   - Analysis of 70% accuracy in clinical context
%   - Comparison with human radiologist performance
%   - Significance relative to existing literature
%   - Analysis of false positives and false negatives

% - **Technical Insights**

%   - Effectiveness of transfer learning from video domain
%   - Value of 3D vs. 2D/3D hybrid approaches
%   - Computational efficiency considerations
%   - Memory constraints and their implications

% - **Model Interpretability** (if implemented)

%   - Insights from XAI analysis
%   - Visualization techniques for model attention/activation
%   - Correlation with known AD-affected regions
%   - Clinical relevance of identified features

% - **Clinical Implications**

%   - Potential utility as a diagnostic aid
%   - Integration into existing clinical workflows
%   - Complementary role to other diagnostic measures

% - **Technical Challenges and Solutions**

%   - Memory optimization strategies
%   - Training time challenges on consumer hardware
%   - Data preprocessing optimization
%   - Hardware limitations and workarounds
%   - Data leakage prevention and subject isolation

% - **Limitations**
%   - Dataset representativeness and potential biases
%   - Focus on binary classification (AD vs. CN)
%   - Technical constraints (resolution, model capacity)
%   - Hardware constraints impact on model selection
%   - Need for prospective validation
%   - Generalizability concerns


\section{Conclusions}
% 1,000 words

% - **Summary of Contributions**

%   - Key findings on transfer learning effectiveness
%   - Revisiting research objectives
%   - Technical innovations in preprocessing pipeline
%   - Methodological contributions (subject-level validation)

% - **Future Directions**

%   - Architectural improvements
%   - Multi-class classification (including MCI)
%   - Multimodal approaches
%   - Longitudinal analysis potential
%   - Clinical validation pathway
%   - Integration of additional MRI sequences
%   - Consideration of larger/deeper architectures with more compute

% - **Broader Impact**
%   - Implications for AI in neuroimaging
%   - Potential for improving AD diagnosis workflow
%   - Ethical considerations and responsible deployment




\bibliographystyle{IEEEtran}
\bibliography{references} 

\appendix

% - **Detailed Implementation Specifics**

%   - Code snippets for key components
%   - Hyperparameter configurations
%   - Detailed architectures

% - **Additional Visualizations**

%   - Extended results tables
%   - Additional performance metrics
%   - Sample preprocessing visualizations
%   - Extended XAI visualizations

% - **Computational Resources Analysis**
%   - Detailed training times
%   - Memory usage patterns
%   - Optimization attempts



\end{document}



